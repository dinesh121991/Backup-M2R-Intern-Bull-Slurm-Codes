<!--#include virtual="header.txt"-->

<h1>Slurm Burst Buffer Guide</h1>

<p><b>DRAFT based upon early design work</b></p>

<p>Slurm version 15.08 includes support for
<a href="http://www.mcs.anl.gov/papers/P2070-0312.pdf">burst buffers</a>,
a shared high-speed storage resource.
Slurm provides support for allocating these resources, staging files in,
scheduling compute nodes for jobs using these resources, then staging files out.
Burst buffers can also be used as temporary storage during a job's lifetime,
without file staging.
Another typical use case is for persist storage, not associated with any
specific job.
This support is provided using a plugin mechanism so that a various burst
buffer infrastructures may be easily configured.
Two plugins are provided initially:</p>
<ol>
<li><b>cray</b> - Uses Cray APIs to perform underlying management functions</li>
<li><b>generic</b> - Uses system administrator defined scripts to perform
underlying management functions</li>
</ol>
<p>Additional plugins may be provided in future releases of Slurm.</p>

<p>Slurm's mode of operation follows this general pattern:</p>
<ol start="0">
<li>Read configuration information and initial state information</li>
<li>After expected start times for pending jobs are established, allocate
    burst buffers to those jobs expected to start earliest and start stage-in
    of required files</li>
<li>After stage-in has completed, jobs can be allocated compute nodes and begin
    execution</li>
<li>After job has completed execution, begin file stage-out from burst buffer</li>
<li>After file stage-out has completed, burst buffer can be released and the
    job record purged
</ol>

<h2>Configuration</h2>

<p>Burst buffer support in Slurm is enabled by specifying the plugin(s) to
loaded for managing these resources using the <i>BurstBufferType</i>
configuration parameter in the <i>slurm.conf</i> file.
Multiple plugin names may be specified in a comma separated list.
Detailed logging of burst buffer specific actions may be generated by using
the <i>DebugFlags=BurstBuffer</i> configuration parameter.
This DebugFlag can result in very verbose logging and is only intended for
diagnostic purposes rather than for use in a production system.</p>

<pre>
# Excerpt of slurm.conf file
BurstBufferType=burst_buffer/generic
DebugFlags=BurstBuffer
</pre>

<p>Burst buffer specific options should be defined in a <i>burst_buffer.conf</i>
file.
This file can contain information about who can or can not use burst buffers,
resource limits, priority boost information for jobs using burst buffers,
timeouts, and paths to script used to perform various functions for the
<i>burst_buffer/generic</i> plugin.
Note that sample scripts for performing these actions are included with the
Slurm distribution.
These scripts were intended for Slurm development and testing purposes and
are <b>not</b> intended for customer use.
Contributions of usable scripts/programs are invited.
For more information about the functionality that might be included in the
scripts, please see
<a href="http://www.k9mach3.org/wickberg-thesis.pdf">
The Ramdisk Storage Accelerator</a>.
Note that these scripts/programs are executed as SlurmUser rather than user
root.
Please see the <i>burst_buffer.conf</i> man page for more information.</p>

<pre>
# Excerpt of burst_buffer.conf file for generic plugin
AllowUsers=alan:brenda
#
JobSizeLimit=20GB   # Applies to each job
UserSizeLimit=50GB  # Applies to ALL users
#
PrioBoostUse=100
PrioBoostAlloc=200
#
StageInTimeout=30
StageOutTimeout=30
#
GetSysState=/usr/local/slurm/15.08/sbin/GSS
StartStageIn=/usr/local/slurm/15.08/sbin/SSI
StartStageOut=/usr/local/slurm/15.08/sbin/SSO
StopStageIn=/usr/local/slurm/15.08/sbin/PSI
StopStageOut=/usr/local/slurm/15.08/sbin/PSO
</pre>

<p><b>Note for Cray systems:</b> The JSON-C library must be installed in order
to build Slurm's burst_buffer/cray plugin, which must parse JSON format data.
See Slurm's <a href="download.html#json">JSON installation information</a>
for details.</p>

<h2>Job Submission Commands</h2>

<p>All of the job submission commands (<i>salloc</i>, <i>sbatch</i> and
<i>srun</i>) accept a "--bb" option to identify burst buffer requirements
by the job.
The normal mode of operation is for batch jobs to specify burst buffer
requirements within the batch script rather than using the "--bb" option.
Batch script lines containing a prefix of "#BB" identify the job's burst buffer
space requirements, files to be staged in, files to be staged out, etc.
Interactive jobs (those submitted using the <i>salloc</i> and <i>srun</i>
commands) can specify their burst buffer space requirements using the "--bb"
option, but staging of jobs before and after the resource allocation is not
supported (e.g. <i>srun --bb=size=10tb my.bash</i>).</p>

<p>Users may also request to be notified by email upon completion of burst
buffer stage out using the "--mail-type=stage_out" or "--mail-type=all" option.
The subject line of the email will be of this form:</p>
<pre>
SLURM Job_id=12 Name=my_app Staged Out, StageOut time 00:05:07
</pre>


<h3>User Options for Generic Plugin</h3>

<p>TBD</p>

<h3>User Options for Cray Plugin</h3>

<p>Note that the normal Slurm job submission commands are used (i.e.
<i>salloc</i>, <i>sbatch</i> and <i>srun</i>).
The burst buffer options in the batch script, identified with a prefix of "#BB",
are passed to Cray software for processing.
See the Cray documentation for details about those options.</p>

<h2>Status Commands</h2>

<p>Slurm's current burst buffer state information is available using the 
<i>scontrol show burst</i> command or by using the <i>sview</i> command's
<i>Burst Buffer</i> tab.</p>

<pre>
$ scontrol show burst
Name=generic Granularity=100GB TotalSpace=50TB UsedSpace=42TB
  JobSizeLimit=10TB UserSizeLimit=40TB
  PrioBoostAlloc=200 PrioBoostUse=100 
  StageInTimeout=30 StageOutTimeout=30 
  AllowUsers=alan:brenda
  GetSysState=/usr/local/slurm/15.08/sbin/GSS
  StartStageIn=/usr/local/slurm/15.08/sbin/SSI
  StartStageIn=/usr/local/slurm/15.08/sbin/SSO
  StopStageIn=/usr/local/slurm/15.08/sbin/PSI
  StopStageIn=/usr/local/slurm/15.08/sbin/PSO
    JobID=18 Size=10TB State=staged-in StateTime=2014-11-19T09:17:21 UserID=alan(1000)
    JobID=20 Size=10TB State=staged-in StateTime=2014-11-19T09:10:42 UserID=alan(1000)
    Name=DB1 Size=22TB State=staged-in StateTime=2014-11-19T09:02:21 UserID=brenda(1001)
</pre>

<h2>Advanced Reservations</h2>

<p>Burst buffer resources can be placed in an advanced reservation using the
<i>BurstBuffer</i> option.
The argument consists of four elements:<br>
[plugin:][type:]#[units]<br>
<i>plugin</i> is the burst buffer plugin name, currently either "cray" or "generic".
If no plugin is specified, the reservation applies to all configured burst
buffer plugins.<br>
<i>type</i> specifies a Cray generic burst buffer resource, for example "nodes".<br>
if "type" is not specified, the number is a measure of storage space.<br>
<i>units</i> may be "N" (nodes), "GB" (gigabytes), "TB" (terabytes),
"PB" (petabytes), etc. with the default units being gigabyes for reservations
of storage space.<br>

Jobs using this reservation are not restricted to these burst buffer resources,
but may use these reserved resources plus any which are generally available.
Some examples follow.</p>

<pre>
$ scontrol create reservation starttime=now duration=60 \
  users=alan flags=any_nodes \
  burstbuffer=cray:100GB,generic:20GB

$ scontrol create reservation StartTime=noon duration=60 \
  users=brenda NodeCnt=8 \
  BurstBuffer=cray:nodes:2,generic:20GB
</pre>

<p style="text-align:center;">Last modified 26 February 2015</p>

<!--#include virtual="footer.txt"-->
